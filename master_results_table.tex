\begin{tabular}{llrrrr}
\toprule
Experiment & Model & Parameters & Val Acc (%) & Train-Val Gap (%) & Avg Epoch Time (s) \\
\midrule
Exp3: Regularization & CNN Dropout=0.5 & 824650 & 92.625000 & 2.493750 & 59.442264 \\
Exp3: Regularization & CNN Dropout=0.3 & 824650 & 92.458333 & 4.360417 & 57.998743 \\
Exp3: Regularization & CNN Dropout=0.2 & 824650 & 92.358333 & 5.395833 & 57.495684 \\
Exp4: Learning Rate & CNN LR=0.001 & 824650 & 91.925000 & 6.639583 & 57.261792 \\
Exp3: Regularization & CNN Dropout=0.0 & 824650 & 91.858333 & 7.045833 & 57.845904 \\
Exp2: CNN Study & Deeper CNN & 824650 & 91.758333 & 7.033333 & 57.610956 \\
Exp4: Learning Rate & CNN LR=0.0001 & 824650 & 91.433333 & 3.431250 & 57.111413 \\
Exp2: CNN Study & Simple CNN & 804554 & 91.316667 & 3.739583 & 23.915127 \\
Exp4: Learning Rate & CNN LR=0.01 & 824650 & 90.725000 & 5.356250 & 56.321397 \\
Exp1: MLP Study & MLP Width=256 & 203530 & 89.400000 & 3.331250 & 0.833364 \\
Exp1: MLP Study & MLP Width=512 & 407050 & 89.333333 & 4.327083 & 1.448957 \\
Exp1: MLP Study & Deep MLP & 242762 & 88.750000 & 4.306250 & 1.108838 \\
Exp1: MLP Study & Simple MLP & 101770 & 88.233333 & 3.270833 & 0.577813 \\
Exp1: MLP Study & MLP Width=128 & 101770 & 88.166667 & 3.458333 & 0.568948 \\
Exp1: MLP Study & MLP Width=64 & 50890 & 88.166667 & 1.539583 & 0.422780 \\
Exp4: Learning Rate & CNN LR=0.1 & 824650 & 85.250000 & 0.995833 & 54.463880 \\
\bottomrule
\end{tabular}
