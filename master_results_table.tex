\begin{tabular}{llrrrr}
\toprule
Experiment & Model & Parameters & Val Acc (%) & Train-Val Gap (%) & Avg Epoch Time (s) \\
\midrule
Exp3: Regularization & CNN Dropout=0.2 & 824650 & 92.466667 & 4.975000 & 24.611721 \\
Exp3: Regularization & CNN Dropout=0.0 & 824650 & 92.366667 & 6.102083 & 24.437210 \\
Exp4: Learning Rate & CNN LR=0.001 & 824650 & 92.350000 & 6.395833 & 24.765170 \\
Exp3: Regularization & CNN Dropout=0.5 & 824650 & 92.291667 & 2.762500 & 25.270441 \\
Exp2: CNN Study & Deeper CNN & 824650 & 92.191667 & 6.518750 & 24.002234 \\
Exp3: Regularization & CNN Dropout=0.3 & 824650 & 92.175000 & 4.581250 & 24.674267 \\
Exp4: Learning Rate & CNN LR=0.01 & 824650 & 91.925000 & 4.616667 & 24.526916 \\
Exp2: CNN Study & Simple CNN & 804554 & 91.475000 & 4.650000 & 11.268552 \\
Exp4: Learning Rate & CNN LR=0.0001 & 824650 & 91.158333 & 3.547917 & 25.002227 \\
Exp1: MLP Study & MLP Width=512 & 407050 & 89.200000 & 4.472917 & 0.644432 \\
Exp1: MLP Study & MLP Width=256 & 203530 & 88.916667 & 3.885417 & 0.381819 \\
Exp1: MLP Study & Simple MLP & 101770 & 88.808333 & 2.908333 & 0.243810 \\
Exp1: MLP Study & Deep MLP & 242762 & 88.425000 & 4.520833 & 0.527911 \\
Exp1: MLP Study & MLP Width=128 & 101770 & 88.366667 & 3.054167 & 0.234448 \\
Exp1: MLP Study & MLP Width=64 & 50890 & 88.100000 & 2.043750 & 0.186719 \\
Exp4: Learning Rate & CNN LR=0.1 & 824650 & 85.875000 & 1.612500 & 23.946940 \\
\bottomrule
\end{tabular}
