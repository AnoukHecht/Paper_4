Experiment,Model,Parameters,Val Acc (%),Train-Val Gap (%),Avg Epoch Time (s)
Exp3: Regularization,CNN Dropout=0.2,824650,92.46666666666667,4.974999999999994,24.611720871925353
Exp3: Regularization,CNN Dropout=0.0,824650,92.36666666666666,6.10208333333334,24.437210369110108
Exp4: Learning Rate,CNN LR=0.001,824650,92.35,6.395833333333343,24.765169537067415
Exp3: Regularization,CNN Dropout=0.5,824650,92.29166666666667,2.7624999999999886,25.270440554618837
Exp2: CNN Study,Deeper CNN,824650,92.19166666666666,6.518749999999997,24.002234303951262
Exp3: Regularization,CNN Dropout=0.3,824650,92.175,4.581249999999997,24.674266934394836
Exp4: Learning Rate,CNN LR=0.01,824650,91.925,4.616666666666674,24.526915967464447
Exp2: CNN Study,Simple CNN,804554,91.475,4.650000000000006,11.268552434444427
Exp4: Learning Rate,CNN LR=0.0001,824650,91.15833333333333,3.5479166666666657,25.00222693681717
Exp1: MLP Study,MLP Width=512,407050,89.2,4.472916666666663,0.6444324731826783
Exp1: MLP Study,MLP Width=256,203530,88.91666666666667,3.885416666666657,0.3818189024925232
Exp1: MLP Study,Simple MLP,101770,88.80833333333334,2.9083333333333314,0.24380989074707032
Exp1: MLP Study,Deep MLP,242762,88.425,4.520833333333343,0.5279110431671142
Exp1: MLP Study,MLP Width=128,101770,88.36666666666666,3.0541666666666742,0.2344476580619812
Exp1: MLP Study,MLP Width=64,50890,88.1,2.043750000000003,0.18671854734420776
Exp4: Learning Rate,CNN LR=0.1,824650,85.875,1.6124999999999972,23.946939611434935
