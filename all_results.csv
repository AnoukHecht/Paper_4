Experiment,Model,Parameters,Val Acc (%),Train-Val Gap (%),Avg Epoch Time (s)
Exp3: Regularization,CNN Dropout=0.5,824650,92.625,2.4937500000000057,59.44226387739182
Exp3: Regularization,CNN Dropout=0.3,824650,92.45833333333333,4.360416666666666,57.99874293804169
Exp3: Regularization,CNN Dropout=0.2,824650,92.35833333333333,5.395833333333329,57.4956839799881
Exp4: Learning Rate,CNN LR=0.001,824650,91.925,6.639583333333334,57.26179175376892
Exp3: Regularization,CNN Dropout=0.0,824650,91.85833333333333,7.045833333333334,57.845904088020326
Exp2: CNN Study,Deeper CNN,824650,91.75833333333334,7.033333333333331,57.610956239700315
Exp4: Learning Rate,CNN LR=0.0001,824650,91.43333333333334,3.4312499999999915,57.111413180828094
Exp2: CNN Study,Simple CNN,804554,91.31666666666666,3.739583333333343,23.91512703895569
Exp4: Learning Rate,CNN LR=0.01,824650,90.725,5.356250000000003,56.32139687538147
Exp1: MLP Study,MLP Width=256,203530,89.4,3.331249999999997,0.8333639144897461
Exp1: MLP Study,MLP Width=512,407050,89.33333333333333,4.327083333333334,1.4489572882652282
Exp1: MLP Study,Deep MLP,242762,88.75,4.306250000000006,1.1088382959365846
Exp1: MLP Study,Simple MLP,101770,88.23333333333333,3.2708333333333286,0.5778125524520874
Exp1: MLP Study,MLP Width=128,101770,88.16666666666667,3.4583333333333286,0.5689480781555176
Exp1: MLP Study,MLP Width=64,50890,88.16666666666667,1.5395833333333258,0.42277987003326417
Exp4: Learning Rate,CNN LR=0.1,824650,85.25,0.9958333333333371,54.46388046741485
